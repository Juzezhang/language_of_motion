NAME: VQVAE_AMASS_Face_256_512_ds4_wo_mesh_lr1e-4 # Experiment names
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
NUM_NODES: 1 # Number of GPU nodes for distributed training
DEVICE: [0] # Index of gpus eg. [0] or [0,1,2,3]

Selected_part: face  # defaut upper
Body_parts:
  upper:
    ori: beat_smplx_joints
    tar: beat_smplx_upper
    vae_test_dim: 78
  lower:
    ori: beat_smplx_joints
    tar: beat_smplx_lower
    vae_test_dim: 61
  lower_54:
    ori: beat_smplx_joints
    tar: beat_smplx_lower
    vae_test_dim: 54
  face:
    ori: beat_smplx_joints
    tar: beat_smplx_face
    vae_test_dim: 106
  full:
    ori: beat_smplx_joints
    tar: beat_smplx_full
    vae_test_dim: 330
  full_new_loss:
    ori: beat_smplx_joints
    tar: beat_smplx_full
    vae_test_dim: 337
  full_h3d:
    ori: beat_smplx_joints
    tar: beat_smplx_full
    vae_test_dim: 263

TRAIN:
  #---------------------------------
  STAGE: vqvae # stage "vae" , "lm_pretrain", "lm_instruct"
  #---------------------------------
  NUM_WORKERS: 4 # Number of workers
  BATCH_SIZE: 32 # Size of batches
  END_EPOCH: 999999 # End epoch
  RESUME: '' # Resume training from this path
  PRETRAINED: '' # Preatrained model path
  PRECISION: '32'
  LOSS_MESH: False  ## whether to use mesh loss for lower and upper body, from experments, looks like not working
  LOSS_6D: False  ## EMAGE paper used rotation matrix as supervision, while here we tried with 6D representation
  OPTIM:
    target: Adam
    params:
      lr: 1e-4
      weight_decay: 0.0

# Evaluating Configuration
EVAL:
  BATCH_SIZE: 1 # Evaluating Batch size
  SPLIT: test

TEST:
  CHECKPOINTS: ./models/pretrained_vq_exp_ds/face/last_325.bin
  SPLIT: test
  TEST_LENGTH: 120
  BATCH_SIZE: 1 # training Batch size


DATASET:
  motion_representation: "rotation" # "rotation" or "h3d"
  target: lom.data.MixedDataset.MixedDataModule
  vary_length: False
  pose_fps: 30
  e_path:  weights/AESKConv_240_100.bin
  e_name: VAESKConv
  datasets:
    - name: "BEAT2" ## For face, only BEAT2 has face data
      stride: 20
      pose_length: 64
      pose_fps: 30
      training_speakers: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]
      additional_data: True # True or False
      pose_rep: smplxflame_30


METRIC:
  TYPE: ['FaceMetrics']
  REGION_PATH: model_files/FLAME2020/FLAME_masks.pkl
  TEMPLATE_PATH: model_files/face_template_no_global.npz

LOSS:
  LAMBDA_FEATURE: 1.0
  LAMBDA_VELOCITY: 0.5
  LAMBDA_COMMIT: 0.02
  LAMBDA_CLS: 1.0
  ABLATION:
    RECONS_LOSS: 'l1_smooth'

model:
  target: lom.models.lom.Language_Motion
  params:
    # condition: 'text'
    task: 't2m'
    # lm: ${lm.lom}
    modality_setup:
      params:
        audio_fps: ${lm.lom.params.audio_samplerate}
        audio_down: ${lm.lom.params.audio_down_sampling}
        motion_fps: ${lm.lom.params.motion_framerate}
        motion_down: ${lm.lom.params.motion_down_sampling}
    modality_tokenizer:
      vae_face:
        target: lom.archs.lom_vq.VQVAEConvZeroDSUS_PaperVersion
        params:
          vae_layer: 3
          code_num: 256
          codebook_size: 512
          vae_quantizer_lambda: 1
          vae_test_dim: ${Body_parts.${Selected_part}.vae_test_dim}  # Dynamic override

LOGGER:
  TYPE: ['wandb']
  VAL_EVERY_STEPS: 10
  WANDB:
    params:
      project: lom