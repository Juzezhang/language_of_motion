NAME: VQVAE_Mixed_Separate_Rot # Experiment names
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
NUM_NODES: 1 # Number of GPU nodes for distributed training
DEVICE: [0,1,2,3] # Index of gpus eg. [0] or [0,1,2,3]

Selected_type: separate_rot  # defaut separate_rot
Representation_type:
  full_h3d:
    ori: beat_smplx_joints
    tar: beat_smplx_full
    vae_test_dim: 263
  full_rot:
    ori: beat_smplx_joints
    tar: beat_smplx_full
    vae_test_dim: 330
  separate_rot:
    face:
      ori: beat_smplx_joints
      tar: beat_smplx_face
      vae_test_dim: 106
    hand:
      ori: beat_smplx_joints
      tar: beat_smplx_hand
      vae_test_dim: 180
    upper:
      ori: beat_smplx_joints
      tar: beat_smplx_upper
      vae_test_dim: 78
    lower:
      ori: beat_smplx_joints
      tar: beat_smplx_lower
      vae_test_dim: 54


TRAIN:
  #---------------------------------
  STAGE: vq # stage "vae", "vq" , "lm_pretrain", "lm_instruct"  similar to motiongpt
  #---------------------------------
  NUM_WORKERS: 16 # Number of workers
  BATCH_SIZE: 64 # Size of batches
  END_EPOCH: 999999 # End epoch
  RESUME: '' # Resume training from this path
  PRETRAINED: '' # Preatrained model path
  PRECISION: 32
  Loss_6D: False
  OPTIM:
    target: Adam
    params:
      lr: 3e-4
      # betas: [0.5, 0.99]
      weight_decay: 0.0

# Evaluating Configuration
EVAL:
  BATCH_SIZE: 1 # Evaluating Batch size
  SPLIT: test

TEST:
  CHECKPOINTS: '/simurgh/u/juze/code/exp_motion/language_of_motion/models/pretrained_vq_exp_ds/vq_ds_paper_version.ckpt'
  # CHECKPOINTS: '/afs/cs.stanford.edu/u/juze/code/exp_motion/language_of_motion/experiments/lom/VQVAE_AMASS_upper_lower_papervision_debug/checkpoints/epoch=109.ckpt'
  SPLIT: test
  BATCH_SIZE: 32 # training Batch size

DATASET:
  motion_representation: ${Selected_type} # "rotation" or "h3d"
  target: lom.data.MixedDataset.MixedDataModule
  smpl_path: models/smpl_models
  vary_length: False
  # pose_length: 40
  test_length: 240
  pose_fps: 30
  e_path:  weights/AESKConv_240_100.bin
  e_name: VAESKConv

  datasets:
    - name: "BEAT2"
      stride: 20
      pose_length: 64
      pose_fps: 30
      code_path: "TOKENS_DS4"
      training_speakers: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]
      additional_data: True # True or False
      pose_rep: smplxflame_30
    - name: "AMASS"
      stride: 20
      pose_length: 64
      pose_fps: 30
      code_path: "TOKENS_DS4"


METRIC:
  TYPE: ['RotationMetrics']


LOSS:
  LAMBDA_FEATURE: 1.0
  LAMBDA_VELOCITY: 0.5
  LAMBDA_COMMIT: 0.02
  LAMBDA_CLS: 1.0
  ABLATION:
    RECONS_LOSS: 'l1_smooth'


model:
  target: lom.models.lom.Language_Motion
  params:
    # condition: 'text'
    # task: 't2m'
    lm: ${lm.default}
    modality_tokenizer:
      vae_face:
        target: lom.archs.lom_vq.VQVAEConvZeroDSUS_PaperVersion
        params:
          vae_layer: 3
          code_num: 256
          codebook_size: 256
          vae_quantizer_lambda: 1
          vae_test_dim: ${Representation_type.${Selected_type}.face.vae_test_dim}  #dynamic
      vae_hand:
        target: lom.archs.lom_vq.VQVAEConvZeroDSUS_PaperVersion
        params:
          vae_layer: 3
          code_num: 256
          codebook_size: 256
          vae_quantizer_lambda: 1
          vae_test_dim: ${Representation_type.${Selected_type}.hand.vae_test_dim}  #dynamic
      vae_upper:
        target: lom.archs.lom_vq.VQVAEConvZeroDSUS_PaperVersion
        params:
          vae_layer: 3
          code_num: 256
          codebook_size: 256
          vae_quantizer_lambda: 1
          vae_test_dim: ${Representation_type.${Selected_type}.upper.vae_test_dim}  #dynamic
      vae_lower:
        target: lom.archs.lom_vq.VQVAEConvZeroDSUS_PaperVersion
        params:
          vae_layer: 3
          code_num: 256
          codebook_size: 256
          vae_quantizer_lambda: 1
          vae_test_dim: ${Representation_type.${Selected_type}.lower.vae_test_dim}  #dynamic
      vae_global:
        target: lom.archs.lom_vq.VAEConvZero
        params:
          vae_layer: 4
          code_num: 256
          codebook_size: 256
          vae_quantizer_lambda: 1
          vae_test_dim: 61
LOGGER:
  TYPE: ['wandb']
  VAL_EVERY_STEPS: 10
  WANDB:
    params:
      project: language_motion
