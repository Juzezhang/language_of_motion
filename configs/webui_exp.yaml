NAME: Webui # Experiment name
DEBUG: False # Debug mode
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
DEVICE: [0] # Index of gpus eg. [0] or [0,1,2,3]

# Training configuration
TRAIN:
  #---------------------------------
  STAGE: lm_instruct
  NUM_WORKERS: 32 # Number of workers
  BATCH_SIZE: 16 # Size of batches
  START_EPOCH: 0 # Start epochMMOTIONENCODER
  END_EPOCH: 99999 # End epoch
  ABLATION:
    pkeep: 0.5
  OPTIM:
    TYPE: AdamW # Optimizer type
    LR: 2e-4 # Learning rate
    WEIGHT_DECAY: 0.0
    LR_SCHEDULER: [100, 200, 300, 400]
    GAMMA: 0.8
  VAE_NAME: VQVAEConvZeroDSUS
  PRETRAINED_VAE_FACE: ./deps/pretrained_vq_exp_ds/face/last_104.bin
  PRETRAINED_VAE_HAND: ./deps/pretrained_vq_exp_ds/hand/last_58.bin
  PRETRAINED_VAE_UPPER: ./deps/pretrained_vq_exp_ds/upper/last_58.bin
  PRETRAINED_VAE_LOWER: ./deps/pretrained_vq_exp_ds/lower/last_58.bin
  PRETRAINED_VAE_GLOBAL: ./deps/pretrained_vq_exp/global/last_280.bin

# Evaluating Configuration
EVAL:
  BATCH_SIZE: 32 # Evaluating Batch size
  SPLIT: test

# Test Configuration
TEST:
#  CHECKPOINTS: experiments/emgpt_emage/Instruct_Mixed_Exp_Ourtoken/checkpoints/last.ckpt
  CHECKPOINTS: experiments/emgpt_emage/Instruct_Mixed_Exp_Ourtoken_Emergent_DS4/checkpoints/epoch=129.ckpt
  #  CHECKPOINTS: experiments/emgpt_emage/Pretrain_Mixed_Exp/checkpoints/epoch=49.ckpt
  SPLIT: test
  BATCH_SIZE: 32 # training Batch size
  MEAN: False
  NUM_SAMPLES:  1
  FACT: 1
#  PRETRAINED_VAE_FACE: ../emage/EMAGE/pretrained_vq/last_790_face_v2.bin
#  PRETRAINED_VAE_HAND: ./deps/pretrained_vq_exp/hand/last_139.bin
#  PRETRAINED_VAE_UPPER: ./deps/pretrained_vq_exp/upper/last_139.bin
#  PRETRAINED_VAE_LOWER: ./deps/pretrained_vq_exp/lower/last_135.bin
#  PRETRAINED_VAE_GLOBAL: ./deps/pretrained_vq_exp/global/last_280.bin
#  PRETRAINED_VAE_HAND: ./deps/pretrained_vq_exp/hand/last_87.bin
#  PRETRAINED_VAE_UPPER: ./deps/pretrained_vq_exp/upper/last_87.bin
#  PRETRAINED_VAE_LOWER: ./deps/pretrained_vq_exp/lower/last_84.bin
#  PRETRAINED_VAE_GLOBAL: ./deps/pretrained_vq_exp/global/pre/last_360.bin

# Datasets Configuration
DATASET:
  target: mGPT.data.webui_exp.MixedDataModule

  datasets:
    - name: "AMASS"
      data_root: "/nas/nas_32/AI-being/zhangjz/exp_motion/datasets/AMASS/"
      type: "amass"
      code_path: "TOKENS"
      instructions_file: "template_instructions_amass.json"
    - name: "BEAT2"
      data_root: "/nas/nas_32/AI-being/zhangjz/exp_motion/datasets/beat2_original/raw_data/beat_v2.0.0/beat_english_v2.0.0/"
      type: "beat2"
      code_path: "TOKENS"
      instructions_file: "template_instructions_beat2.json"

  vary_length: True

  CODE_PATH: TOKENS
  smpl_path: deps/smpl_models
  training_speakers: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30] #[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]
  additional_data: False
  cache_path: datasets/beat_cache/beat_smplx_en_emage/
  e_path:  weights/AESKConv_240_100.bin
  e_name: VAESKConv
  new_cache: False
  multi_length_training: [1.0]
  disable_filtering: False
  clean_first_seconds: 0
  clean_final_seconds: 0
  selected_file: None

  # motion config
  ori_joints: beat_smplx_joints
  tar_joints: beat_smplx_full
  pose_rep: smplxflame_30
  pose_norm: False
  pose_fps: 30
  rot6d: True
  pre_frames: 4
  pose_dims: 330
  pose_length: 64
  stride: 20
  test_length: 64
  motion_f: 256
  m_pre_encoder: null
  m_encoder: null
  m_fix_pre: False
  beat_align: True
  # facial config
  facial_rep: smplxflame_30
  facial_dims: 100
  facial_norm: False
  facial_f: 0
  f_pre_encoder: null
  f_encoder: null
  f_fix_pre: False

  # speaker config
  id_rep: onehot
  speaker_f: 0

  # audio config
  audio_rep: onset+amplitude
  audio_sr: 16000
  audio_fps: 16000
  audio_norm: False
  audio_f: 256
  # a_pre_encoder: tcn_camn
  # a_encoder: none
  # a_fix_pre: False

  # text config
  word_rep: textgrid
  word_index_num: 11195
  word_dims: 300
  freeze_wordembed: False
  word_f: 256
  t_pre_encoder: fasttext
  t_encoder: null
  t_fix_pre: False

METRIC:
  TYPE: ['TM2TMetrics']
# Losses Configuration
LOSS:
  TYPE: t2mgpt # Losses type
  LAMBDA_FEATURE: 1.0
  LAMBDA_VELOCITY: 0.5
  LAMBDA_COMMIT: 0.02
  LAMBDA_CLS: 1.0
  LAMBDA_M2T2M: 1.0
  LAMBDA_T2M2T: 10.0
  ABLATION:
    RECONS_LOSS: 'l1_smooth'

# Model Configuration
model:
  target: mGPT.models.emgpt_emage_webui.ExpressionalMotionGPT
  params:
    condition: 'text'
    task: 'a2m'
    lm: ${lm.emgpt_flash_attention}
#    lm: ${lm.emgpt_flash_attention_t2m}
#    lm: ${lm.emgpt_flash_attention_t2m_32}
    motion_vae: ${vq.emage}
    audio_setup:
      params:
        audio_samplerate: 16000
        audio_down: 320
# Logger configuration
LOGGER:
  LOG_EVERY_STEPS: 5
  VAL_EVERY_STEPS: 10
  TENSORBOARD: True
  wandb:
    params:
      project: null
